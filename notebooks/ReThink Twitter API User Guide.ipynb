{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369a90b2",
   "metadata": {},
   "source": [
    "# ReThink Media Twitter API: Tutorial and Examples\n",
    "\n",
    "This notebook will provide a user manual and example use cases for using ReThink Media's Twitter API functions. The functions in this notebook will provide the capabilities to:\n",
    "- Search Tweets relevant to a query, over different time periods\n",
    "- Save Tweets and Tweet metadata to a .csv file for later reference and use\n",
    "- Create wordclouds for frequent keywords and hashtags\n",
    "- Create plots of Tweet counts over time, with adjustable titles and axes\n",
    "\n",
    "As an example use case for these functions, this notebook will compare the discussions around the coming out of two transgender celebrities: Caitlin Jenner and Elliot Page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5cf1dc",
   "metadata": {},
   "source": [
    "## Defining Functions\n",
    "\n",
    "The first part of this notebook is dedicated to defining and explaining the functions mentioned above, with the example use case to follow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a8be65",
   "metadata": {},
   "source": [
    "### Authentication & Utility Functions\n",
    "\n",
    "These functions are utility functions that are embedded within the main ones, and must be initialized before the others are used. Run the cells below before running the other functions.\n",
    "\n",
    "**IMPORTANT NOTE:** The Twitter API requires API keys and other authentication tokens in order to function properly. A user must have a Twitter Developer account with these keys available in order to use the functions in this notebook. If you have these keys available, create a text file named `.env` in the home folder for your notebook environment with the following format:\n",
    "\n",
    "```\n",
    "API_KEY=\"your_api_key\"\n",
    "API_KEY_SECRET=\"your_secret_api_key\"\n",
    "BEARER_TOKEN=\"your_bearer_token\"\n",
    "ACCESS_TOKEN=\"your_access_token\"\n",
    "ACCESS_SECRET=\"your_secret_access_token\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f0554f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to initialize Twitter API v1.1 instance (for 30-day and full archive search)\n",
    "def init_api_1():\n",
    "    \n",
    "    # importing necessary modules and loading .env file\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    import tweepy\n",
    "    load_dotenv()\n",
    "    \n",
    "    # retrieving environment variables from .env file\n",
    "    consumer_key = os.getenv(\"API_KEY\")\n",
    "    consumer_secret = os.getenv(\"API_KEY_SECRET\")\n",
    "    bearer_token = os.getenv(\"BEARER_TOKEN\")\n",
    "    access_token = os.getenv(\"ACCESS_TOKEN\")\n",
    "    access_secret = os.getenv(\"ACCESS_SECRET\")\n",
    "    \n",
    "    # Twitter API authentication\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    \n",
    "    # instantiating Twitter API v1.1 reference\n",
    "    api_1 = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "    \n",
    "    return api_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11e7c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to initialize Twitter API v2 instance (for 7-day search)\n",
    "def init_api_2():\n",
    "    # importing necessary modules and loading .env file\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    import tweepy\n",
    "    load_dotenv()\n",
    "    \n",
    "    # retrieving environment variables from .env file\n",
    "    consumer_key = os.getenv(\"API_KEY\")\n",
    "    consumer_secret = os.getenv(\"API_KEY_SECRET\")\n",
    "    bearer_token = os.getenv(\"BEARER_TOKEN\")\n",
    "    access_token = os.getenv(\"ACCESS_TOKEN\")\n",
    "    access_secret = os.getenv(\"ACCESS_SECRET\")\n",
    "    \n",
    "    # instantiating Twitter API v2 reference\n",
    "    api_2 = tweepy.Client(bearer_token=bearer_token,\n",
    "                         consumer_key=consumer_key,\n",
    "                         consumer_secret=consumer_secret,\n",
    "                         access_token=access_token,\n",
    "                         access_token_secret=access_secret,\n",
    "                         wait_on_rate_limit=True)\n",
    "    \n",
    "    return api_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34877376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to parse Twitter API v2 response into a DataFrame of Tweet data\n",
    "def tweet_df(df, response, tweet_fields):\n",
    "    \n",
    "    users = response.includes['users']\n",
    "    user_data = {user['id']: [user['public_metrics']['followers_count'], user['verified']] for user in users}\n",
    "        \n",
    "    # looping through each Tweet in response, parsing data\n",
    "    for i in range(len(response.data)):\n",
    "        tweet = response.data[i]\n",
    "        tweet_id = tweet.id\n",
    "        tweet_data = {}\n",
    "        for field in tweet_fields:\n",
    "            if tweet[field]:\n",
    "                tweet_data[field] = tweet[field]\n",
    "                \n",
    "                # extracting hashtags from \"entities\" field and adding it as its own column\n",
    "                if field == \"entities\":\n",
    "                    try:\n",
    "                        hashtag_data = tweet[field]['hashtags']\n",
    "                        hashtags = [hashtag['tag'] for hashtag in hashtag_data]\n",
    "                        tweet_data['entities_hashtags'] = hashtags\n",
    "                    except KeyError:\n",
    "                        tweet_data['entities_hashtags'] = None\n",
    "                \n",
    "                # separating metrics from \"public_metrics\" field and adding them as their own column\n",
    "                if field == \"public_metrics\":\n",
    "                    metrics = list(tweet[field].keys())\n",
    "                    for metric in metrics:\n",
    "                        tweet_data[metric] = tweet[field][metric]\n",
    "                \n",
    "            else:\n",
    "                tweet_data[field] = None\n",
    "                if field == \"entities\":\n",
    "                    tweet_data['entities_hashtags'] = None\n",
    "        \n",
    "        # adding user data to DataFrame\n",
    "        user = user_data[tweet['author_id']]\n",
    "        tweet_data['followers_count'] = user[0]\n",
    "        tweet_data['verified'] = user[1]\n",
    "        \n",
    "        df.loc[tweet_id] = tweet_data\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60029452",
   "metadata": {},
   "source": [
    "### Tweet Search Functions\n",
    "\n",
    "The Twitter API has different limits on how many API requests a user can make and how many Tweets they can receive, depending on how far back the user wants to search. For this reason, there are three different Tweet search functions, and the user should choose the function that best fits their use case:\n",
    "\n",
    "- `search_7()`: Search Tweets within the past 7 days. Unlimited API requests, 500,000 Tweets per month.\n",
    "- `search_30()`: Search Tweets within the past 30 days. 250 API requests, 25,000 Tweets per month.\n",
    "- `search_full()`: Search Tweets from the full archive. 50 API requests, 5,000 Tweets per month.\n",
    "\n",
    "The Twitter API also has a limit of 100 API requests per 15-minute interval, regardless of which function is used. If the quota runs out, the functions will wait until the time limit resets, and then continue collecting Tweets.\n",
    "\n",
    "The arguments for these functions are:\n",
    "- `query`: The query to search the Twitter API for\n",
    "- `start_date`: The date to start the search (default `None`). If `None`, the function will default to 7 days ago.\n",
    "- `end_date`: The date to end the search (default `None`). If `None`, the function will default to today.\n",
    "- `max_results`: The maximum amount of Tweets to return in the DataFrame (default 20).\n",
    "- `write_csv`: Boolean, whether to save the DataFrame as a csv file or not. Default `False`.\n",
    "- `filename`: Filename for the csv if `write_csv` is `True`. Default name is `search_7.csv`, `search_30.csv`, or `search_full.csv`, depending on the function used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "914e98f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve Tweets from the past 7 days relevant to a query\n",
    "def search_7(query, start_date=None, end_date=None, max_results=20, write_csv=False, filename=\"search_7.csv\"):\n",
    "    \n",
    "    # initializing API v1.1 instance\n",
    "    api_2 = init_api_2()\n",
    "    \n",
    "    # parsing dates passed into function\n",
    "    from dateutil import parser\n",
    "    from datetime import datetime\n",
    "    if start_date:\n",
    "        start_date = parser.parse(start_date)\n",
    "        start_date = start_date.strftime(\"%Y%m%d%H%M\")\n",
    "    if end_date:\n",
    "        end_date = parser.parse(end_date)\n",
    "        end_date = end_date.strftime(\"%Y%m%d%H%M\")\n",
    "    \n",
    "    # setting Tweet and user data to be included in response\n",
    "    tweet_fields = [\"text\", \"attachments\", \"author_id\", \"context_annotations\", \"conversation_id\", \"created_at\",\n",
    "                   \"entities\", \"geo\", \"in_reply_to_user_id\", \"lang\", \"public_metrics\", \"referenced_tweets\"]\n",
    "    user_fields = [\"public_metrics\", \"verified\"]\n",
    "    \n",
    "    # initializing variables for API calls and DataFrame for Tweet data\n",
    "    import pandas as pd\n",
    "    next_token = None\n",
    "    num_tweets = 0\n",
    "    tweets = pd.DataFrame(columns=tweet_fields+['followers_count', 'verified']+\n",
    "                          ['entities_hashtags','retweet_count','reply_count','like_count','quote_count'])\n",
    "    tweets.index.name = \"Tweet ID\"\n",
    "    \n",
    "    # making my own pagination loop to further examine the rate limit\n",
    "    num_loops = 0\n",
    "    while num_tweets < max_results:\n",
    "        \n",
    "        # the API only retrieves between 10 and 100 Tweets per call\n",
    "        # NOTE: number of API results isn't consistent. max_results=100 doesn't guarantee 100 Tweets in response\n",
    "        if max_results - num_tweets >= 100:\n",
    "            num_results = 100\n",
    "        else:\n",
    "            num_results = max_results - num_tweets if max_results - num_tweets > 10 else 10\n",
    "        \n",
    "        # calling API and searching Tweets over past 7 days\n",
    "        response = api_2.search_recent_tweets(f\"{query} lang:en\", \n",
    "                                              start_time=start_date,\n",
    "                                              end_time=end_date,\n",
    "                                              max_results=num_results,\n",
    "                                              next_token=next_token,\n",
    "                                              tweet_fields=tweet_fields,\n",
    "                                              expansions='author_id',\n",
    "                                              user_fields=user_fields)\n",
    "        \n",
    "        # setting variables for the next loop\n",
    "        try:\n",
    "            next_token = response[3]['next_token']\n",
    "        except KeyError:\n",
    "            next_token = None\n",
    "        num_tweets += len(response.data)\n",
    "        num_loops += 1\n",
    "        \n",
    "        # adding Tweet data to DataFrame\n",
    "        tweets = tweet_df(tweets, response, tweet_fields)\n",
    "        \n",
    "    # dropping \"public_metrics\" since all the values are unpacked, adding \"total_engagements\"\n",
    "    tweets.drop('public_metrics', axis=1, inplace=True)\n",
    "    total_engagements = tweets[\"retweet_count\"] + tweets[\"reply_count\"] + tweets[\"like_count\"] + tweets[\"quote_count\"]\n",
    "    tweets[\"total_engagements\"] = total_engagements\n",
    "        \n",
    "    # writing Tweet DataFrame to csv file\n",
    "    if write_csv:\n",
    "        tweets.to_csv(filename)\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e33d649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to search Tweets within the past 30 days\n",
    "# utilizes both API v1.1 and v2 to be consistent with 7-day search.\n",
    "def search_30(query, start_date=None, end_date=None, max_results=20, write_csv=False, filename=\"search_30.csv\"):\n",
    "    # initializing API v1.1 instance\n",
    "    api_1 = init_api_1()\n",
    "    \n",
    "    # parsing dates passed into function\n",
    "    from dateutil import parser\n",
    "    from datetime import datetime\n",
    "    if start_date:\n",
    "        start_date = parser.parse(start_date)\n",
    "        start_date = start_date.strftime(\"%Y%m%d%H%M\")\n",
    "    if end_date:\n",
    "        end_date = parser.parse(end_date)\n",
    "        end_date = end_date.strftime(\"%Y%m%d%H%M\")\n",
    "    \n",
    "    # retrieving Tweets from the past 30 days relevant to query using tweepy's pagination function\n",
    "    import tweepy\n",
    "    response_1 = tweepy.Cursor(api_1.search_30_day,\n",
    "                               label=\"30day\",\n",
    "                               query=f\"{query} lang:en\",\n",
    "                               fromDate=start_date,\n",
    "                               toDate=end_date,\n",
    "                               maxResults=100\n",
    "                              ).items(max_results)\n",
    "    \n",
    "    # gathering Tweet ID's in a list\n",
    "    print(response_1)\n",
    "    tweet_ids = [tweet._json['id'] for tweet in response_1]\n",
    "    \n",
    "    # setting Tweet data to be included in response_2\n",
    "    tweet_fields = [\"text\", \"attachments\", \"author_id\", \"context_annotations\", \"conversation_id\", \"created_at\",\n",
    "                   \"entities\", \"geo\", \"in_reply_to_user_id\", \"lang\", \"public_metrics\", \"referenced_tweets\"]\n",
    "    user_fields = [\"public_metrics\", \"verified\"]\n",
    "    \n",
    "    # initializing variables for API v2 calls and DataFrame for Tweet data\n",
    "    import pandas as pd\n",
    "    num_tweets = 0\n",
    "    tweets = pd.DataFrame(columns=tweet_fields+['followers_count', 'verified']+\n",
    "                          ['entities_hashtags','retweet_count','reply_count','like_count','quote_count'])    \n",
    "    tweets.index.name = \"Tweet ID\"\n",
    "    \n",
    "    # loop to retrieve Tweets from ID's through API v2, 100 at a time\n",
    "    api_2 = init_api_2()\n",
    "    \n",
    "    while num_tweets < max_results:\n",
    "        # slicing tweet_ids since API v2 get_tweets only takes max 100 ID's per request\n",
    "        try:\n",
    "            slice_ids = tweet_ids[num_tweets:num_tweets+100]\n",
    "        except IndexError:\n",
    "            slice_ids = tweet_ids[num_tweets:]\n",
    "        if len(slice_ids) == 0:\n",
    "            break\n",
    "\n",
    "        # retrieving Tweet data from API v2 and adding to DataFrame\n",
    "        response_2 = api_2.get_tweets(slice_ids, tweet_fields=tweet_fields, \n",
    "                                      expansions='author_id', user_fields=user_fields)\n",
    "        tweets = tweet_df(tweets, response_2, tweet_fields)\n",
    "        num_tweets += len(response_2.data)\n",
    "    \n",
    "    # dropping \"public_metrics\" since all the values are unpacked, adding \"total_engagements\"\n",
    "    tweets.drop('public_metrics', axis=1, inplace=True)\n",
    "    total_engagements = tweets[\"retweet_count\"] + tweets[\"reply_count\"] + tweets[\"like_count\"] + tweets[\"quote_count\"]\n",
    "    tweets[\"total_engagements\"] = total_engagements\n",
    "    \n",
    "    # writing Tweet DataFrame to csv file\n",
    "    if write_csv:\n",
    "        tweets.to_csv(filename)\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "547bfe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to search Tweets within the full Tweet archive\n",
    "# utilizes both API v1.1 and v2 to be consistent with 7-day search.\n",
    "def search_full(query, start_date=None, end_date=None, max_results=20, write_csv=False, filename=\"search_full.csv\"):\n",
    "    # initializing API v1.1 instance\n",
    "    api_1 = init_api_1()\n",
    "    \n",
    "    # parsing dates passed into function\n",
    "    from dateutil import parser\n",
    "    from datetime import datetime\n",
    "    if start_date:\n",
    "        start_date = parser.parse(start_date)\n",
    "        start_date = start_date.strftime(\"%Y%m%d%H%M\")\n",
    "    if end_date:\n",
    "        end_date = parser.parse(end_date)\n",
    "        end_date = end_date.strftime(\"%Y%m%d%H%M\")\n",
    "    \n",
    "    # retrieving Tweets from the full tweet archive relevant to query using tweepy's pagination function\n",
    "    import tweepy\n",
    "    response_1 = tweepy.Cursor(api_1.search_full_archive,\n",
    "                               label=\"full\",\n",
    "                               query=f\"{query} lang:en\",\n",
    "                               fromDate=start_date,\n",
    "                               toDate=end_date,\n",
    "                               maxResults=100\n",
    "                              ).items(max_results)\n",
    "    \n",
    "    # gathering Tweet ID's in a list\n",
    "    tweet_ids = [tweet._json['id'] for tweet in response_1]\n",
    "    \n",
    "    # setting Tweet data to be included in response\n",
    "    tweet_fields = [\"text\", \"attachments\", \"author_id\", \"context_annotations\", \"conversation_id\", \"created_at\",\n",
    "                   \"entities\", \"geo\", \"in_reply_to_user_id\", \"lang\", \"public_metrics\", \"referenced_tweets\"]\n",
    "    user_fields = [\"public_metrics\", \"verified\"]\n",
    "    \n",
    "    # initializing variables for API calls and DataFrame for Tweet data\n",
    "    import pandas as pd\n",
    "    tweets = pd.DataFrame(columns=tweet_fields+[\"followers_count\", \"verified\"]+\n",
    "                          ['entities_hashtags','retweet_count','reply_count','like_count','quote_count'])\n",
    "    tweets.index.name = \"Tweet ID\"\n",
    "    \n",
    "    # loop to retrieve Tweets from ID's through API v2, 100 at a time\n",
    "    api_2 = init_api_2()\n",
    "    num_tweets = 0\n",
    "    while num_tweets < max_results:\n",
    "        # slicing tweet_ids since API v2 get_tweets only takes max 100 ID's per request\n",
    "        try:\n",
    "            slice_ids = tweet_ids[num_tweets:num_tweets+100]\n",
    "        except IndexError:\n",
    "            slice_ids = tweet_ids[num_tweets:]\n",
    "        if len(slice_ids) == 0:\n",
    "            break\n",
    "\n",
    "        # retrieving Tweet data from API v2 and adding to DataFrame\n",
    "        response_2 = api_2.get_tweets(slice_ids, tweet_fields=tweet_fields,\n",
    "                                     expansions='author_id', user_fields=user_fields)\n",
    "        tweets = tweet_df(tweets, response_2, tweet_fields)\n",
    "        num_tweets += len(response_2.data)\n",
    "    \n",
    "    # dropping \"public_metrics\" since all the values are unpacked, adding \"total_engagements\"\n",
    "    tweets.drop('public_metrics', axis=1, inplace=True)\n",
    "    total_engagements = tweets[\"retweet_count\"] + tweets[\"reply_count\"] + tweets[\"like_count\"] + tweets[\"quote_count\"]\n",
    "    tweets[\"total_engagements\"] = total_engagements\n",
    "    \n",
    "    # writing Tweets DataFrame to csv file\n",
    "    if write_csv:\n",
    "        tweets.to_csv(filename)\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22137c70",
   "metadata": {},
   "source": [
    "### Wordclouds\n",
    "\n",
    "This function creates wordclouds for frequent words and hashtags in Tweet data. To avoid making any unnecessary API calls, this function takes the DataFrame created from the search functions as an input. The arguments for this function are:\n",
    "\n",
    "- `df`: DataFrame of Tweet data, created from one of the Tweet search functions defined above.\n",
    "- `query`: The query used to create `df`. If passed into the function, `query` is added to the stop words for the word cloud, so they aren't added to the cloud.\n",
    "- `save_imgs`: Boolean, whether to save the images to a file or not. The filenames will be `wordcloud.png` and `hashtags.png` in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbb3568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cloud(df, query=None, save_imgs=False):\n",
    "    # combining DataFrame text column into one long string, doing some initial pre-processing\n",
    "    import pandas as pd\n",
    "    tweet_text = \" \".join(df[\"text\"])\n",
    "    tweet_text = tweet_text.lower()\n",
    "    tweet_text = tweet_text.replace(\"\\n\", \" \")\n",
    "    \n",
    "    # splitting string into set of words, removing hashtags, usernames, links, and retweet indicator\n",
    "    word_list = set(tweet_text.split(\" \"))\n",
    "    hash_list = {word for word in word_list if word.startswith(\"#\")}\n",
    "    user_list = {word for word in word_list if word.startswith(\"@\")}\n",
    "    link_list = {word for word in word_list if word.startswith(\"http\")}\n",
    "    word_list = {word for word in word_list if word not in hash_list.union(user_list, link_list)}\n",
    "    word_list = {word for word in word_list if word != \"rt\"}\n",
    "    \n",
    "    # using nltk tokenizer to further pre-process text, removing non-alpha words\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "    tweet_text = \" \".join(word_list)\n",
    "    word_list = word_tokenize(tweet_text)\n",
    "    word_list = {word for word in word_list if word.isalpha()}\n",
    "    \n",
    "    # joining list of words into final cleaned string\n",
    "    tweet_text = \" \".join(word_list)\n",
    "    \n",
    "    # generating word cloud\n",
    "    from wordcloud import WordCloud, STOPWORDS\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    stopwords = set(STOPWORDS)\n",
    "    \n",
    "    # adding words from query to stop words so they don't show up in the word cloud\n",
    "    if query:\n",
    "        stopwords.update(query.split())\n",
    "\n",
    "    # word cloud for text\n",
    "    words_fig = plt.figure()\n",
    "    word_cloud = WordCloud(background_color=\"white\", width=3000, height=2000, max_font_size=500,\n",
    "                           max_words=100, prefer_horizontal=1.0, stopwords=stopwords)\n",
    "    word_cloud.generate(tweet_text)\n",
    "    plt.imshow(word_cloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Frequent keywords in Tweets\", fontsize=15)\n",
    "    plt.show()\n",
    "    if save_imgs:\n",
    "        word_cloud.to_file(\"wordcloud.png\")\n",
    "\n",
    "    # word cloud for hashtags\n",
    "    hash_fig = plt.figure()\n",
    "    word_cloud = WordCloud(background_color=\"white\", width=3000, height=2000, max_font_size=500,\n",
    "                           max_words=100, prefer_horizontal=1.0, stopwords=stopwords)\n",
    "    word_cloud.generate(\" \".join(hash_list))\n",
    "    plt.imshow(word_cloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Frequent hashtags in Tweets\", fontsize=15)\n",
    "    plt.show()\n",
    "    if save_imgs:\n",
    "        word_cloud.to_file(\"hashtags.png\")\n",
    "    \n",
    "    return words_fig, hash_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c7690f",
   "metadata": {},
   "source": [
    "### Attention Over Time Plots\n",
    "\n",
    "This function plots the volume of tweets relevant to a query over time. Similar to the wordcloud function, this function avoids additional API calls and takes the DataFrame from the Tweet search functions as an input. The user can adjust aspects of the plot to fit different use cases, such as the title, plot type, and x-axis labels. The arguments for this function are:\n",
    "\n",
    "- `df`: DataFrame of Tweet data, created from one of the Tweet search functions defined above.\n",
    "- `query`: The query used to create `df`. If passed into this function, adds a subtitle to the plot with the query.\n",
    "- `title`: The title of the plot.\n",
    "- `xlabel`: \"month\", \"year\", or \"day\" (default \"month\"). Granularity of ticks and labels on the x-axis.\n",
    "- `plot_type`: \"line\" or \"bar\" (default \"line\"). Choose between line or bar plot for attention over time.\n",
    "- `figsize`: Default (10,5). Size of the figure outputted by this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29f3aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot function\n",
    "def attention_plots(df, query=None, title=\"Tweet count over time\", xlabel=\"month\", plot_type=\"line\", figsize=(10,5)):\n",
    "    \n",
    "    # ensuring the correct parameters have been passed\n",
    "    assert plot_type in (\"line\", \"bar\"), \"Please input 'line' or 'bar' into plot_type\"\n",
    "    assert xlabel in (\"day\", \"month\", \"year\"), \"Please input 'day', 'month', or 'year' into xlabel\"\n",
    "        \n",
    "    # converting dates to datetime, getting counts of tweets per day\n",
    "    import pandas as pd\n",
    "    df[\"created_at\"] = pd.to_datetime(df[\"created_at\"])\n",
    "    daily_counts = test.groupby(test[\"created_at\"].dt.date).count()\n",
    "    dates = pd.to_datetime(daily_counts.index)\n",
    "    \n",
    "    # creating figure for plot\n",
    "    import matplotlib.pyplot as plt\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "    \n",
    "    # line or bar graph, depending on input\n",
    "    if plot_type == \"line\":\n",
    "        plt.plot(daily_counts.index, daily_counts[\"text\"])\n",
    "    else:\n",
    "        plt.bar(daily_counts.index, daily_counts[\"text\"])\n",
    "    \n",
    "    # setting x-axis ticks to be month, day, or year, depending on input\n",
    "    if xlabel == \"month\":\n",
    "        period = \"M\"\n",
    "        tick_labels = dates.to_period(period).unique().strftime(\"%b %Y\")\n",
    "    elif xlabel == \"day\":\n",
    "        period = \"D\"\n",
    "        tick_labels = dates.to_period(period).unique().strftime(\"%m-%d-%Y\")\n",
    "    elif xlabel == \"year\":\n",
    "        period = \"Y\"\n",
    "        tick_labels = dates.to_period(period).unique()\n",
    "    tick_locs = dates.to_period(period).unique()\n",
    "    plt.xticks(ticks=tick_locs, labels=tick_labels, rotation=90)\n",
    "    \n",
    "    # setting plot title and subtitle (if query is passed)\n",
    "    plt.suptitle(title, fontsize=15)\n",
    "    if query:\n",
    "        plt.title(f\"Query: {query}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Number of Tweets\")\n",
    "    plt.show()\n",
    "    \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c0146e",
   "metadata": {},
   "source": [
    "## Example Use Case: Caitlin Jenner & Elliot Page\n",
    "\n",
    "The rest of the notebook will walk through an example use case for these functions: comparing the discussions around Caitlin Jenner and Elliot Page when they came out as transgender. The example will use all of the functions defined above as a simple baseline for users to see how they work and what their outputs are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf2b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing functions from rethink_twitter_functions.py\n",
    "from rethink_twitter_functions import *\n",
    "\n",
    "# importing a module so we can time how long the functions take\n",
    "import time\n",
    "\n",
    "# defining some search strings for the API queries\n",
    "page_search = '\"elliot page\"'\n",
    "jenn_search = '\"caitlin jenner\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff259fb5",
   "metadata": {},
   "source": [
    "### Current relevance\n",
    "\n",
    "We can get an initial idea about the difference in how these two celebrities are viewed by looking at what people are saying about them. We can use the `search_7()` function to see how people are talking about these celebrities right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e05cf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.34371581077575686 min\n",
      "\"elliot page\" mentioned 264 times\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>attachments</th>\n",
       "      <th>author_id</th>\n",
       "      <th>context_annotations</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>geo</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>entities_hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>total_engagements</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tweet ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1461442602889355268</th>\n",
       "      <td>anyway, there's new elliot page pics. in case ...</td>\n",
       "      <td>None</td>\n",
       "      <td>772915432017702912</td>\n",
       "      <td>[{'domain': {'id': '10', 'name': 'Person', 'de...</td>\n",
       "      <td>1461442462082342913</td>\n",
       "      <td>2021-11-18 21:14:03+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>772915432017702912</td>\n",
       "      <td>en</td>\n",
       "      <td>[(type, id)]</td>\n",
       "      <td>1306</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461442233140346881</th>\n",
       "      <td>elliot page my beloved the light of my life ht...</td>\n",
       "      <td>{'media_keys': ['3_1461442228530782211', '3_14...</td>\n",
       "      <td>1328850303710420993</td>\n",
       "      <td>[{'domain': {'id': '10', 'name': 'Person', 'de...</td>\n",
       "      <td>1461442233140346881</td>\n",
       "      <td>2021-11-18 21:12:35+00:00</td>\n",
       "      <td>{'urls': [{'start': 44, 'end': 67, 'url': 'htt...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>298</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461442155713417220</th>\n",
       "      <td>A story of homoerotic sex in 1950s New York. S...</td>\n",
       "      <td>None</td>\n",
       "      <td>1110200174398312448</td>\n",
       "      <td>[{'domain': {'id': '10', 'name': 'Person', 'de...</td>\n",
       "      <td>1461442155713417220</td>\n",
       "      <td>2021-11-18 21:12:16+00:00</td>\n",
       "      <td>{'annotations': [{'start': 29, 'end': 42, 'pro...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>245</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461435798700572672</th>\n",
       "      <td>@MiaOnSunday The child in that netflix show, h...</td>\n",
       "      <td>None</td>\n",
       "      <td>715859536</td>\n",
       "      <td>[{'domain': {'id': '10', 'name': 'Person', 'de...</td>\n",
       "      <td>1461431449370906625</td>\n",
       "      <td>2021-11-18 20:47:01+00:00</td>\n",
       "      <td>{'annotations': [{'start': 31, 'end': 37, 'pro...</td>\n",
       "      <td>None</td>\n",
       "      <td>61092130</td>\n",
       "      <td>en</td>\n",
       "      <td>[(type, id)]</td>\n",
       "      <td>1039</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461427587431940097</th>\n",
       "      <td>@llorithaine If you haven’t seen Whip It w Ell...</td>\n",
       "      <td>None</td>\n",
       "      <td>1423074082715750401</td>\n",
       "      <td>[{'domain': {'id': '10', 'name': 'Person', 'de...</td>\n",
       "      <td>1461426094431735814</td>\n",
       "      <td>2021-11-18 20:14:23+00:00</td>\n",
       "      <td>{'annotations': [{'start': 43, 'end': 53, 'pro...</td>\n",
       "      <td>None</td>\n",
       "      <td>1423074082715750401</td>\n",
       "      <td>en</td>\n",
       "      <td>[(type, id)]</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "Tweet ID                                                                 \n",
       "1461442602889355268  anyway, there's new elliot page pics. in case ...   \n",
       "1461442233140346881  elliot page my beloved the light of my life ht...   \n",
       "1461442155713417220  A story of homoerotic sex in 1950s New York. S...   \n",
       "1461435798700572672  @MiaOnSunday The child in that netflix show, h...   \n",
       "1461427587431940097  @llorithaine If you haven’t seen Whip It w Ell...   \n",
       "\n",
       "                                                           attachments  \\\n",
       "Tweet ID                                                                 \n",
       "1461442602889355268                                               None   \n",
       "1461442233140346881  {'media_keys': ['3_1461442228530782211', '3_14...   \n",
       "1461442155713417220                                               None   \n",
       "1461435798700572672                                               None   \n",
       "1461427587431940097                                               None   \n",
       "\n",
       "                               author_id  \\\n",
       "Tweet ID                                   \n",
       "1461442602889355268   772915432017702912   \n",
       "1461442233140346881  1328850303710420993   \n",
       "1461442155713417220  1110200174398312448   \n",
       "1461435798700572672            715859536   \n",
       "1461427587431940097  1423074082715750401   \n",
       "\n",
       "                                                   context_annotations  \\\n",
       "Tweet ID                                                                 \n",
       "1461442602889355268  [{'domain': {'id': '10', 'name': 'Person', 'de...   \n",
       "1461442233140346881  [{'domain': {'id': '10', 'name': 'Person', 'de...   \n",
       "1461442155713417220  [{'domain': {'id': '10', 'name': 'Person', 'de...   \n",
       "1461435798700572672  [{'domain': {'id': '10', 'name': 'Person', 'de...   \n",
       "1461427587431940097  [{'domain': {'id': '10', 'name': 'Person', 'de...   \n",
       "\n",
       "                         conversation_id                created_at  \\\n",
       "Tweet ID                                                             \n",
       "1461442602889355268  1461442462082342913 2021-11-18 21:14:03+00:00   \n",
       "1461442233140346881  1461442233140346881 2021-11-18 21:12:35+00:00   \n",
       "1461442155713417220  1461442155713417220 2021-11-18 21:12:16+00:00   \n",
       "1461435798700572672  1461431449370906625 2021-11-18 20:47:01+00:00   \n",
       "1461427587431940097  1461426094431735814 2021-11-18 20:14:23+00:00   \n",
       "\n",
       "                                                              entities   geo  \\\n",
       "Tweet ID                                                                       \n",
       "1461442602889355268                                               None  None   \n",
       "1461442233140346881  {'urls': [{'start': 44, 'end': 67, 'url': 'htt...  None   \n",
       "1461442155713417220  {'annotations': [{'start': 29, 'end': 42, 'pro...  None   \n",
       "1461435798700572672  {'annotations': [{'start': 31, 'end': 37, 'pro...  None   \n",
       "1461427587431940097  {'annotations': [{'start': 43, 'end': 53, 'pro...  None   \n",
       "\n",
       "                     in_reply_to_user_id lang referenced_tweets  \\\n",
       "Tweet ID                                                          \n",
       "1461442602889355268   772915432017702912   en      [(type, id)]   \n",
       "1461442233140346881                 None   en              None   \n",
       "1461442155713417220                 None   en              None   \n",
       "1461435798700572672             61092130   en      [(type, id)]   \n",
       "1461427587431940097  1423074082715750401   en      [(type, id)]   \n",
       "\n",
       "                    followers_count verified entities_hashtags retweet_count  \\\n",
       "Tweet ID                                                                       \n",
       "1461442602889355268            1306    False              None             0   \n",
       "1461442233140346881             298    False              None             0   \n",
       "1461442155713417220             245    False              None             0   \n",
       "1461435798700572672            1039    False              None             0   \n",
       "1461427587431940097              30    False              None             0   \n",
       "\n",
       "                    reply_count like_count quote_count total_engagements  \n",
       "Tweet ID                                                                  \n",
       "1461442602889355268           0          0           0                 0  \n",
       "1461442233140346881           0          0           0                 0  \n",
       "1461442155713417220           0          0           0                 0  \n",
       "1461435798700572672           1          0           0                 1  \n",
       "1461427587431940097           0          1           0                 1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running and timing the search_7 function for Elliot Page \n",
    "start = time.time()\n",
    "page_7 = search_7(page_search, max_results=2000, write_csv=True)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time taken: {(end-start)/60} min\")\n",
    "print(f'{page_search} mentioned {len(page_7)} times')\n",
    "page_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d49ee129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1:\n",
      "@GaymerExtofer @Asymetricalhomo @A_hungry_Fool @jeffbrutlag @ASm1thee Elliot Page addressed that directly.\n",
      "\n",
      "It’s a fair question to ask, and it’s his prerogative to respond (or not). From there, we can take it as it is. I don’t know if Chrispy is anti, but if he wants the benefit of ambiguity he also has to deal with the repercussions of ambiguity. https://t.co/elRGEChCWe \n",
      "\n",
      "Tweet 2:\n",
      "@LynchRegan Also I haaaaaaate being called king - feels like something an overly woke cis girl would call Elliot page when she’s performing her allyship a little too hard \n",
      "\n",
      "Tweet 3:\n",
      "RT @lizardkingfe: @graceelavery look I wasn’t expecting grand insights into life as a butch lesbian from Graham, but you can tell he’s only… \n",
      "\n",
      "Tweet 4:\n",
      "Actors\n",
      "Cara Delevingne (Pan, Genderfluid She/Her)\n",
      "Elliot Page (Trans man He/They)\n",
      "Jack Dylan Grazer (Bi He/They)\n",
      "Auli’i Cravalho (Bi She/Her) https://t.co/fQjdc4tS2O \n",
      "\n",
      "Tweet 5:\n",
      "@PotatoSoup13 I DONT WANT A LADY TO TELL ME THAT THE CONGRESS SHOULD STOP ROE V WADE AND THEN WATCH A BUNCH OF PODCAST MEN MISGENDER ELLIOT PAGE NO! \n",
      "\n",
      "Tweet 6:\n",
      "RT @Goldxn_Violin: Young Elliot Page gimme ur gender https://t.co/RhwQDPRPsf \n",
      "\n",
      "Tweet 7:\n",
      "@AdeleCarlyon @Ikn0Ihcas0 @JeimesD Yep-all the holly trans are resorting back to their original biological sex. Add Elliot page to that roster... \n",
      "\n",
      "Tweet 8:\n",
      "the day y’all stop treating elliot page like hes 12 will be the day we progress as a society \n",
      "\n",
      "Tweet 9:\n",
      "idk who is in charge but someone should cast Elliot Page in an Alien movie \n",
      "\n",
      "Tweet 10:\n",
      "Coffee and the thrill of Elliot Page coming out as trans \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# showing samples of tweets within DataFrame\n",
    "page_sample = page_7.sample(n=10)\n",
    "num_tweets = 1\n",
    "for tweet in page_sample.text:\n",
    "    print(f\"Tweet {num_tweets}:\")\n",
    "    print(tweet,\"\\n\")\n",
    "    num_tweets += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b073d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.32984480063120525 min\n",
      "\"caitlin jenner\" mentioned 119 times\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>attachments</th>\n",
       "      <th>author_id</th>\n",
       "      <th>context_annotations</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>geo</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>entities_hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>total_engagements</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tweet ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1461426121560449025</th>\n",
       "      <td>RT @JennaferNyx: @BalkusAnthony There's a reas...</td>\n",
       "      <td>None</td>\n",
       "      <td>1363319341958094849</td>\n",
       "      <td>None</td>\n",
       "      <td>1461426121560449025</td>\n",
       "      <td>2021-11-18 20:08:34+00:00</td>\n",
       "      <td>{'annotations': [{'start': 79, 'end': 92, 'pro...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>[(type, id)]</td>\n",
       "      <td>1046</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461425986222923778</th>\n",
       "      <td>@BalkusAnthony There's a reason why transphobe...</td>\n",
       "      <td>None</td>\n",
       "      <td>1363319341958094849</td>\n",
       "      <td>None</td>\n",
       "      <td>1461422207117131777</td>\n",
       "      <td>2021-11-18 20:08:01+00:00</td>\n",
       "      <td>{'annotations': [{'start': 62, 'end': 75, 'pro...</td>\n",
       "      <td>None</td>\n",
       "      <td>1394862254621958147</td>\n",
       "      <td>en</td>\n",
       "      <td>[(type, id)]</td>\n",
       "      <td>1046</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461421012587884550</th>\n",
       "      <td>@Mrjjrocks @dog_envier The difference between ...</td>\n",
       "      <td>None</td>\n",
       "      <td>1012719733</td>\n",
       "      <td>None</td>\n",
       "      <td>1461062447276564480</td>\n",
       "      <td>2021-11-18 19:48:15+00:00</td>\n",
       "      <td>{'annotations': [{'start': 181, 'end': 194, 'p...</td>\n",
       "      <td>None</td>\n",
       "      <td>195049592</td>\n",
       "      <td>en</td>\n",
       "      <td>[(type, id)]</td>\n",
       "      <td>669</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461415036090347522</th>\n",
       "      <td>@MrJGPozos @TheRealAndrew_ Ok would you vote f...</td>\n",
       "      <td>None</td>\n",
       "      <td>781830667436863488</td>\n",
       "      <td>None</td>\n",
       "      <td>1392653546600939523</td>\n",
       "      <td>2021-11-18 19:24:31+00:00</td>\n",
       "      <td>{'annotations': [{'start': 49, 'end': 62, 'pro...</td>\n",
       "      <td>None</td>\n",
       "      <td>1068317205736185856</td>\n",
       "      <td>en</td>\n",
       "      <td>[(type, id)]</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461413793846550529</th>\n",
       "      <td>@LibQn32 @ciara Seems they have a celebrity fo...</td>\n",
       "      <td>None</td>\n",
       "      <td>2885584092</td>\n",
       "      <td>[{'domain': {'id': '10', 'name': 'Person', 'de...</td>\n",
       "      <td>1461395756221407238</td>\n",
       "      <td>2021-11-18 19:19:34+00:00</td>\n",
       "      <td>{'annotations': [{'start': 103, 'end': 106, 'p...</td>\n",
       "      <td>None</td>\n",
       "      <td>1015448038989619201</td>\n",
       "      <td>en</td>\n",
       "      <td>[(type, id)]</td>\n",
       "      <td>259</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "Tweet ID                                                                 \n",
       "1461426121560449025  RT @JennaferNyx: @BalkusAnthony There's a reas...   \n",
       "1461425986222923778  @BalkusAnthony There's a reason why transphobe...   \n",
       "1461421012587884550  @Mrjjrocks @dog_envier The difference between ...   \n",
       "1461415036090347522  @MrJGPozos @TheRealAndrew_ Ok would you vote f...   \n",
       "1461413793846550529  @LibQn32 @ciara Seems they have a celebrity fo...   \n",
       "\n",
       "                    attachments            author_id  \\\n",
       "Tweet ID                                               \n",
       "1461426121560449025        None  1363319341958094849   \n",
       "1461425986222923778        None  1363319341958094849   \n",
       "1461421012587884550        None           1012719733   \n",
       "1461415036090347522        None   781830667436863488   \n",
       "1461413793846550529        None           2885584092   \n",
       "\n",
       "                                                   context_annotations  \\\n",
       "Tweet ID                                                                 \n",
       "1461426121560449025                                               None   \n",
       "1461425986222923778                                               None   \n",
       "1461421012587884550                                               None   \n",
       "1461415036090347522                                               None   \n",
       "1461413793846550529  [{'domain': {'id': '10', 'name': 'Person', 'de...   \n",
       "\n",
       "                         conversation_id                created_at  \\\n",
       "Tweet ID                                                             \n",
       "1461426121560449025  1461426121560449025 2021-11-18 20:08:34+00:00   \n",
       "1461425986222923778  1461422207117131777 2021-11-18 20:08:01+00:00   \n",
       "1461421012587884550  1461062447276564480 2021-11-18 19:48:15+00:00   \n",
       "1461415036090347522  1392653546600939523 2021-11-18 19:24:31+00:00   \n",
       "1461413793846550529  1461395756221407238 2021-11-18 19:19:34+00:00   \n",
       "\n",
       "                                                              entities   geo  \\\n",
       "Tweet ID                                                                       \n",
       "1461426121560449025  {'annotations': [{'start': 79, 'end': 92, 'pro...  None   \n",
       "1461425986222923778  {'annotations': [{'start': 62, 'end': 75, 'pro...  None   \n",
       "1461421012587884550  {'annotations': [{'start': 181, 'end': 194, 'p...  None   \n",
       "1461415036090347522  {'annotations': [{'start': 49, 'end': 62, 'pro...  None   \n",
       "1461413793846550529  {'annotations': [{'start': 103, 'end': 106, 'p...  None   \n",
       "\n",
       "                     in_reply_to_user_id lang referenced_tweets  \\\n",
       "Tweet ID                                                          \n",
       "1461426121560449025                 None   en      [(type, id)]   \n",
       "1461425986222923778  1394862254621958147   en      [(type, id)]   \n",
       "1461421012587884550            195049592   en      [(type, id)]   \n",
       "1461415036090347522  1068317205736185856   en      [(type, id)]   \n",
       "1461413793846550529  1015448038989619201   en      [(type, id)]   \n",
       "\n",
       "                    followers_count verified entities_hashtags retweet_count  \\\n",
       "Tweet ID                                                                       \n",
       "1461426121560449025            1046    False              None             1   \n",
       "1461425986222923778            1046    False              None             1   \n",
       "1461421012587884550             669    False              None             0   \n",
       "1461415036090347522              52    False              None             0   \n",
       "1461413793846550529             259    False              None             0   \n",
       "\n",
       "                    reply_count like_count quote_count total_engagements  \n",
       "Tweet ID                                                                  \n",
       "1461426121560449025           0          0           0                 1  \n",
       "1461425986222923778           1          2           0                 4  \n",
       "1461421012587884550           1          0           0                 1  \n",
       "1461415036090347522           1          0           0                 1  \n",
       "1461413793846550529           0          0           0                 0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running and timing the search_7 function for Caitlin Jenner\n",
    "start = time.time()\n",
    "jenn_7 = search_7(jenn_search, max_results=2000, write_csv=True)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time taken: {(end-start)/60} min\")\n",
    "print(f'{jenn_search} mentioned {len(jenn_7)} times')\n",
    "jenn_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f99c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1:\n",
      "yall realise you can hate caitlin jenner without insulting her appearance or being transphobic right? just so we all clear \n",
      "\n",
      "Tweet 2:\n",
      "@Tribe_XX Caitlin Jenner . Oh my \n",
      "\n",
      "Tweet 3:\n",
      "known murderer caitlin jenner would like a word https://t.co/hc9aiuKnSX \n",
      "\n",
      "Tweet 4:\n",
      "@rsosa8 Caitlin Jenner\n",
      "Serena Williams \n",
      "Angelina Jolie\n",
      "\n",
      "Tom Brady\n",
      "Nolan Ryan \n",
      "Mick Jagger \n",
      "\n",
      "Tweet 5:\n",
      "@SteMcC82 @SullyTrent @Ryanyates10 @20StoriesMCR No, it's a joke about Caitlin Jenner, not about trans people. \n",
      "\n",
      "Tweet 6:\n",
      "@salsaboiii Adrian Adonis 2.0. Golddust..just a Bruce Jenner out there kicking ass..Sorry, Caitlin Jenner kicking ass. I like this storyline. \n",
      "\n",
      "Tweet 7:\n",
      "@libsoftiktok Caitlin Jenner didn’t win the California governor’s race do to anti-trans California.  We all know California hates trans people\n",
      "#Californiaismid \n",
      "\n",
      "Tweet 8:\n",
      "@ItsOnlyMara20 @MusoniusRufus @questionbot1776 @SimpleArgonian @incompleteocean @Aly_Dar8 @Lynnia00721169 @acneonmyshirt @thatwitchyjess7 @maqart55 @shanoawarrior @Architectprod @chronic_chels @NewStyle303 @smashli1228 @JaneKn0wsBest @virginia_house @StephFeminist @BootsChantilly @BarrennessBlack @JGainsbourgh @feloneouscat @SlaggitySlag @blackcat476 @mc78784383 @Drowssap12 @SierraDeciduous @Arachne646 @ArchivingIt @PickleMrs @PupperMum @atriana @HedwigGraymalk @doccynzl @Dentatus2 @Rust13Suzanne @GregCampNC Maybe he’s dreaming about Caitlin Jenner. 🙄😂 \n",
      "\n",
      "Tweet 9:\n",
      "@sevatividam23 I would smack Caitlin Jenner in the face if I ever met her. 😂😂 \n",
      "\n",
      "Tweet 10:\n",
      "RT @reactjpg: caitlin jenner holding lqbtq let’s get biden to quit shirt https://t.co/cgy4ox5Q2o \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# showing samples of tweets within DataFrame\n",
    "jenn_sample = jenn_7.sample(n=10)\n",
    "num_tweets = 1\n",
    "for tweet in jenn_sample.text:\n",
    "    print(f\"Tweet {num_tweets}:\")\n",
    "    print(tweet,\"\\n\")\n",
    "    num_tweets += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8308a3d",
   "metadata": {},
   "source": [
    "Elliot Page has been mentioned 264 times in the past week, whereas Caitlin Jenner has been mentioned 119 times. From the samples that we've displayed, it also seems like Elliot Page is held in higher regard than Caitlin Jenner on Twitter. We only display 10 samples for each celebrity though, so the samples may not be representative of the rest of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cfad68",
   "metadata": {},
   "source": [
    "### Names and deadnames\n",
    "\n",
    "We can get an idea of how much these two celebrities' identities are respected by looking at how many times they are referenced by their \"deadname.\" A deadname is the birth name that a transgender person drops when they transition, often in favor of a name that fits their gender. We can use the `search_30()` function to get an idea about how Elliot and Caitlin are viewed in the public eye, whether they are more referenced by their chosen name or their deadname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f3f4b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.22551111777623495 min\n",
      "Elliot Page has been deadnamed 946 times\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>attachments</th>\n",
       "      <th>author_id</th>\n",
       "      <th>context_annotations</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>geo</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>entities_hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>total_engagements</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tweet ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1460316351428448256</th>\n",
       "      <td>RT @ZacballsPages: Ellen’s Spooky Streak page ...</td>\n",
       "      <td>{'media_keys': ['3_1454481459998302213']}</td>\n",
       "      <td>1391282073957134338</td>\n",
       "      <td>[{'domain': {'id': '119', 'name': 'Holiday', '...</td>\n",
       "      <td>1460316351428448256</td>\n",
       "      <td>2021-11-15 18:38:44+00:00</td>\n",
       "      <td>{'mentions': [{'start': 3, 'end': 17, 'usernam...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>[(type, id)]</td>\n",
       "      <td>39</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460275011600715783</th>\n",
       "      <td>@NNecroz @JustMightyJake That’s the studio beh...</td>\n",
       "      <td>None</td>\n",
       "      <td>4550081715</td>\n",
       "      <td>None</td>\n",
       "      <td>1460267304768442373</td>\n",
       "      <td>2021-11-15 15:54:28+00:00</td>\n",
       "      <td>{'mentions': [{'start': 0, 'end': 8, 'username...</td>\n",
       "      <td>None</td>\n",
       "      <td>1029475334847164417</td>\n",
       "      <td>en</td>\n",
       "      <td>[(type, id)]</td>\n",
       "      <td>62</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460243624025751554</th>\n",
       "      <td>RT @Feet_Addicted_: Kate Mara &amp;amp; Ellen Page...</td>\n",
       "      <td>{'media_keys': ['7_1186737271959101442']}</td>\n",
       "      <td>1199255575843889152</td>\n",
       "      <td>[{'domain': {'id': '10', 'name': 'Person', 'de...</td>\n",
       "      <td>1460243624025751554</td>\n",
       "      <td>2021-11-15 13:49:44+00:00</td>\n",
       "      <td>{'mentions': [{'start': 3, 'end': 18, 'usernam...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>en</td>\n",
       "      <td>[(type, id)]</td>\n",
       "      <td>91</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460236132860497930</th>\n",
       "      <td>@Bolt_451 Elliot Page (née Ellen) was sitting ...</td>\n",
       "      <td>None</td>\n",
       "      <td>17558699</td>\n",
       "      <td>[{'domain': {'id': '10', 'name': 'Person', 'de...</td>\n",
       "      <td>1459527379131502595</td>\n",
       "      <td>2021-11-15 13:19:58+00:00</td>\n",
       "      <td>{'mentions': [{'start': 0, 'end': 9, 'username...</td>\n",
       "      <td>None</td>\n",
       "      <td>20631467</td>\n",
       "      <td>en</td>\n",
       "      <td>[(type, id)]</td>\n",
       "      <td>456</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460206967352446979</th>\n",
       "      <td>@dreangr selective professionalism huh. Facebo...</td>\n",
       "      <td>None</td>\n",
       "      <td>1308376862184402944</td>\n",
       "      <td>[{'domain': {'id': '46', 'name': 'Brand Catego...</td>\n",
       "      <td>1460193267245625344</td>\n",
       "      <td>2021-11-15 11:24:05+00:00</td>\n",
       "      <td>{'mentions': [{'start': 0, 'end': 8, 'username...</td>\n",
       "      <td>None</td>\n",
       "      <td>1371651491921080320</td>\n",
       "      <td>en</td>\n",
       "      <td>[(type, id)]</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "Tweet ID                                                                 \n",
       "1460316351428448256  RT @ZacballsPages: Ellen’s Spooky Streak page ...   \n",
       "1460275011600715783  @NNecroz @JustMightyJake That’s the studio beh...   \n",
       "1460243624025751554  RT @Feet_Addicted_: Kate Mara &amp; Ellen Page...   \n",
       "1460236132860497930  @Bolt_451 Elliot Page (née Ellen) was sitting ...   \n",
       "1460206967352446979  @dreangr selective professionalism huh. Facebo...   \n",
       "\n",
       "                                                   attachments  \\\n",
       "Tweet ID                                                         \n",
       "1460316351428448256  {'media_keys': ['3_1454481459998302213']}   \n",
       "1460275011600715783                                       None   \n",
       "1460243624025751554  {'media_keys': ['7_1186737271959101442']}   \n",
       "1460236132860497930                                       None   \n",
       "1460206967352446979                                       None   \n",
       "\n",
       "                               author_id  \\\n",
       "Tweet ID                                   \n",
       "1460316351428448256  1391282073957134338   \n",
       "1460275011600715783           4550081715   \n",
       "1460243624025751554  1199255575843889152   \n",
       "1460236132860497930             17558699   \n",
       "1460206967352446979  1308376862184402944   \n",
       "\n",
       "                                                   context_annotations  \\\n",
       "Tweet ID                                                                 \n",
       "1460316351428448256  [{'domain': {'id': '119', 'name': 'Holiday', '...   \n",
       "1460275011600715783                                               None   \n",
       "1460243624025751554  [{'domain': {'id': '10', 'name': 'Person', 'de...   \n",
       "1460236132860497930  [{'domain': {'id': '10', 'name': 'Person', 'de...   \n",
       "1460206967352446979  [{'domain': {'id': '46', 'name': 'Brand Catego...   \n",
       "\n",
       "                         conversation_id                created_at  \\\n",
       "Tweet ID                                                             \n",
       "1460316351428448256  1460316351428448256 2021-11-15 18:38:44+00:00   \n",
       "1460275011600715783  1460267304768442373 2021-11-15 15:54:28+00:00   \n",
       "1460243624025751554  1460243624025751554 2021-11-15 13:49:44+00:00   \n",
       "1460236132860497930  1459527379131502595 2021-11-15 13:19:58+00:00   \n",
       "1460206967352446979  1460193267245625344 2021-11-15 11:24:05+00:00   \n",
       "\n",
       "                                                              entities   geo  \\\n",
       "Tweet ID                                                                       \n",
       "1460316351428448256  {'mentions': [{'start': 3, 'end': 17, 'usernam...  None   \n",
       "1460275011600715783  {'mentions': [{'start': 0, 'end': 8, 'username...  None   \n",
       "1460243624025751554  {'mentions': [{'start': 3, 'end': 18, 'usernam...  None   \n",
       "1460236132860497930  {'mentions': [{'start': 0, 'end': 9, 'username...  None   \n",
       "1460206967352446979  {'mentions': [{'start': 0, 'end': 8, 'username...  None   \n",
       "\n",
       "                     in_reply_to_user_id lang referenced_tweets  \\\n",
       "Tweet ID                                                          \n",
       "1460316351428448256                 None   en      [(type, id)]   \n",
       "1460275011600715783  1029475334847164417   en      [(type, id)]   \n",
       "1460243624025751554                 None   en      [(type, id)]   \n",
       "1460236132860497930             20631467   en      [(type, id)]   \n",
       "1460206967352446979  1371651491921080320   en      [(type, id)]   \n",
       "\n",
       "                    followers_count verified entities_hashtags retweet_count  \\\n",
       "Tweet ID                                                                       \n",
       "1460316351428448256              39    False              None            11   \n",
       "1460275011600715783              62    False              None             0   \n",
       "1460243624025751554              91    False              None           109   \n",
       "1460236132860497930             456    False              None             0   \n",
       "1460206967352446979              34    False              None             0   \n",
       "\n",
       "                    reply_count like_count quote_count total_engagements  \n",
       "Tweet ID                                                                  \n",
       "1460316351428448256           0          0           0                11  \n",
       "1460275011600715783           1          0           0                 1  \n",
       "1460243624025751554           0          0           0               109  \n",
       "1460236132860497930           0          0           0                 0  \n",
       "1460206967352446979           1          1           0                 2  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running and timing the search_30 function for Elliot Page \n",
    "start = time.time()\n",
    "page_dn = search_30(\"ellen page\", max_results=3000, write_csv=True)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time taken: {(end-start)/60} min\")\n",
    "print(f'Elliot Page has been deadnamed {len(page_dn)} times')\n",
    "page_dn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5829615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tweepy.cursor.ItemIterator object at 0x7fce3f3a4e50>\n"
     ]
    },
    {
     "ename": "TooManyRequests",
     "evalue": "429 Too Many Requests\nRequest exceeds account’s current package request limits. Please upgrade your package and retry or contact Twitter about enterprise access.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7749/1137606824.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# running and timing the search_30 function for Caitlin Jenner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjenn_dn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_30\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bruce jenner\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_csv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7749/4103650699.py\u001b[0m in \u001b[0;36msearch_30\u001b[0;34m(query, start_date, end_date, max_results, write_csv, filename)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# gathering Tweet ID's in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtweet_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# setting Tweet data to be included in response_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7749/4103650699.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# gathering Tweet ID's in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtweet_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# setting Tweet data to be included in response_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.9/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.9/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.9/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.9/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_token\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_cursors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.9/site-packages/tweepy/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpagination_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.9/site-packages/tweepy/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payload_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payload_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.9/site-packages/tweepy/api.py\u001b[0m in \u001b[0;36msearch_30_day\u001b[0;34m(self, label, query, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdeveloper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpremium\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpremium\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \"\"\"\n\u001b[0;32m--> 363\u001b[0;31m         return self.request(\n\u001b[0m\u001b[1;32m    364\u001b[0m             'GET', f'tweets/search/30day/{label}', endpoint_parameters=(\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34m'query'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fromDate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'toDate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'maxResults'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'next'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/twitter/lib/python3.9/site-packages/tweepy/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m429\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTooManyRequests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTwitterServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTooManyRequests\u001b[0m: 429 Too Many Requests\nRequest exceeds account’s current package request limits. Please upgrade your package and retry or contact Twitter about enterprise access."
     ]
    }
   ],
   "source": [
    "# running and timing the search_30 function for Caitlin Jenner \n",
    "start = time.time()\n",
    "jenn_dn = search_30(\"bruce jenner\", max_results=3000, write_csv=True)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time taken: {(end-start)/60} min\")\n",
    "print(f'Caitlin Jenner has been deadnamed {len(jenn_dn)} times')\n",
    "jenn_dn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd67734",
   "metadata": {},
   "source": [
    "In the past month, Elliot Page has been deadnamed 946 times, and Caitlin Jenner has been deadnamed so much that the Twitter API threw an error trying to retrieve all of the Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad234c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
